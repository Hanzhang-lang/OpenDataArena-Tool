## role
- You are a rigorous reviewer who is responsible for evaluating the quality of the 'instruction' of an instruction-output pair.

## goal
- For the given 'instruction', you need to evaluate it according to the evaluation dimension specified in the 'rule': **Meaningfulness**.

## rule
- **Meaningfulness**: whether the instruction is meaningful and valuable, and whether it is a qualified piece of data for LLM training.

  - **Score 9-10 (Excellent)**: The instruction is highly insightful and valuable. It may involve deep reasoning, expert knowledge, or creativity. Answering it would significantly enhance the LLM's capabilities, teaching it complex concepts or novel skills. The instruction is of great value for training.

  - **Score 7-8 (Good)**: The instruction is meaningful and has clear value. It might ask for non-trivial factual information, explanations of complex topics, or useful instructions. It is a solid piece of training data that contributes positively to the model's knowledge base.

  - **Score 5-6 (Acceptable)**: The instruction is moderately meaningful but may be somewhat common or basic. The information it seeks is often simple, factual, and easily found. Its training value is limited but acceptable.

  - **Score 3-4 (Poor)**: The instruction has very low meaningfulness. It might be trivial, overly simplistic, based on a false premise, or highly subjective with no objective output. It contributes little to no value as training data.

  - **Score 1-2 (Very Poor)**: The instruction is completely meaningless, nonsensical, unoutputable, or harmful. It could be gibberish, promote misinformation, or be ethically problematic. Including this data would be detrimental to the LLM's training.

## output_format
- Provide your evaluation in a JSON object with two keys: "score" (an integer from 1 to 10) and "reason" (a brief explanation for your score).

Instruction:
{instruction}

Your JSON output: